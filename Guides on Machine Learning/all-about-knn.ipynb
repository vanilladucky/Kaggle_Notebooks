{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f10ea28",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:38.112666Z",
     "iopub.status.busy": "2022-08-09T23:04:38.112263Z",
     "iopub.status.idle": "2022-08-09T23:04:38.132082Z",
     "shell.execute_reply": "2022-08-09T23:04:38.131216Z"
    },
    "papermill": {
     "duration": 0.035447,
     "end_time": "2022-08-09T23:04:38.133976",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.098529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/red-wine-dataset/wineQualityInfo.txt\n",
      "/kaggle/input/red-wine-dataset/wineQualityReds.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946b4b2",
   "metadata": {
    "papermill": {
     "duration": 0.010691,
     "end_time": "2022-08-09T23:04:38.155950",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.145259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Welcome to a full guide on K-nearest Neighbor ðŸ¤©ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f0252",
   "metadata": {
    "papermill": {
     "duration": 0.011461,
     "end_time": "2022-08-09T23:04:38.178310",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.166849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### K-nearest Neighbor, more well known as simply just KNN is a very simple and intuitive machine learning algorithm. \n",
    "#### I wouldn't say it is a very powerful nor efficient one but it is good to keep it in your arsenal just in case. \n",
    "#### As usual, I will show you the mathematics behind this intuitive algorithm and end this off with some written code to illustrate you how the algorithm is made.\n",
    "#### Now I know I've used the word 'intuitive' twice, but that's for a reason you shall soon see. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c53faa",
   "metadata": {
    "papermill": {
     "duration": 0.010526,
     "end_time": "2022-08-09T23:04:38.199767",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.189241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Shall we dive in then?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf1ac02",
   "metadata": {
    "papermill": {
     "duration": 0.010531,
     "end_time": "2022-08-09T23:04:38.221000",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.210469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://images.unsplash.com/photo-1527588574470-7152d7c3c15e?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxzZWFyY2h8OHx8ZGl2ZSUyMGlufGVufDB8fDB8fA%3D%3D&auto=format&fit=crop&w=500&q=60\" style=\"width:50%;height:50%;margin:auto;\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622fc55",
   "metadata": {
    "papermill": {
     "duration": 0.010541,
     "end_time": "2022-08-09T23:04:38.242222",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.231681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12723ba",
   "metadata": {
    "papermill": {
     "duration": 0.010697,
     "end_time": "2022-08-09T23:04:38.263698",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.253001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Some obvious questions you should have in mind when learning or using KNN is, what on earth does the K mean? \n",
    "#### Now before we jump into that section, let me briefly explain to you the traits of this algorithm. \n",
    "#### I always believe in a top-down approach to learning as you get to learn the basics/big picture before jumping into the tiny details that define this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18b7a98",
   "metadata": {
    "papermill": {
     "duration": 0.010858,
     "end_time": "2022-08-09T23:04:38.285501",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.274643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Some notable traits of KNN algorithm is as such \n",
    "* It is sensitive to feature scales\n",
    "* Can be used for both classification and regression \n",
    "* Supervised Learning\n",
    "* Non-parametric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534bdd96",
   "metadata": {
    "papermill": {
     "duration": 0.010708,
     "end_time": "2022-08-09T23:04:38.307313",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.296605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Allow me to briefly explain to you the points above.\n",
    "#### KNN is sensitive to unbalanced scaling in the feature variables due to its method of finding the K neighbors.\n",
    "#### KNN calculates the distance between points to obtain these neighbors and thus obviously differently scaled features will affect this very distance. \n",
    "#### Therefore when using KNN, the user must always remember to scale the features.\n",
    "#### One very famous method is to just standardize the features, which means ensuring the mean is 0 with unit standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6945d6",
   "metadata": {
    "papermill": {
     "duration": 0.010727,
     "end_time": "2022-08-09T23:04:38.328863",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.318136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Yes, KNN can be also used for regression but is mainly a classification algorithm, thus I will be sticking with KNN for classification in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c0777a",
   "metadata": {
    "papermill": {
     "duration": 0.010506,
     "end_time": "2022-08-09T23:04:38.350100",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.339594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### KNN is indeed a supervised learning algorithm. \n",
    "#### This means that there must be a target variables along with the usual feature variables that we have. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643a27a",
   "metadata": {
    "papermill": {
     "duration": 0.010503,
     "end_time": "2022-08-09T23:04:38.371300",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.360797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Finally, and I woul say is the most important trait, KNN is a non-parametric algorithm.\n",
    "#### To understand this, one would first need to understand what a parametric and non-parametric algorithm is.\n",
    "#### A parametric algorithm is one that relies on sets of weights and biases (parameters) to predict final results. These parameters can span from just a handful to million, like those we see in deep neural networks.\n",
    "#### On the other hand, a non-parmaetric algorithm has no trainable parameters at all. It doesn't have any weights or biases but uses simple comparison techniques or other similiar ways to obtain an outcome.\n",
    "#### So with this understood, remember that KNN is a **non-parametric** algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49356582",
   "metadata": {
    "papermill": {
     "duration": 0.010584,
     "end_time": "2022-08-09T23:04:38.392573",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.381989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Now I have explained the traits of KNN, let us dive into the main mechanics of this algorithm and how it obtains the desired results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e3cbd9",
   "metadata": {
    "papermill": {
     "duration": 0.010588,
     "end_time": "2022-08-09T23:04:38.413842",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.403254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e934ec99",
   "metadata": {
    "papermill": {
     "duration": 0.01047,
     "end_time": "2022-08-09T23:04:38.434927",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.424457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Now the explanation of KNN is going to be shorter than the other models since it is a very simple algorithm. \n",
    "#### You will see why I keep saying this. \n",
    "#### But it's not all simple and great because as I said before, it isn't the most efficient. \n",
    "#### That is the reason why you don't see this algorithm being employed in a large scale classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a67ca4",
   "metadata": {
    "papermill": {
     "duration": 0.010578,
     "end_time": "2022-08-09T23:04:38.456197",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.445619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Ok with those 'disclaimers' out of the way, let me show you how this algorithm works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd01896",
   "metadata": {
    "papermill": {
     "duration": 0.010631,
     "end_time": "2022-08-09T23:04:38.477733",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.467102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The basic idea is this: From a dataset, we will find the k number of nearest datapoints to the specific datapoint and then assign the class that the majority of the neighboring datapoints possess.\n",
    "#### To find the k nearest neighboring datapoints, we need to have a distance metric, and in this case that would mostly be the [Euclidean Distance](https://en.wikipedia.org/wiki/Euclidean_distance) as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f58793",
   "metadata": {
    "papermill": {
     "duration": 0.010607,
     "end_time": "2022-08-09T23:04:38.499215",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.488608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$$\\LARGE d\\left( p,q\\right)   = \\sqrt {\\sum _{i=1}^{n}  \\left( q_{i}-p_{i}\\right)^2 } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a72aa4",
   "metadata": {
    "papermill": {
     "duration": 0.010903,
     "end_time": "2022-08-09T23:04:38.521256",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.510353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The above formula concerns finding the distance between two datapoints, namely p and q. \n",
    "#### The calculation consists of deducting every dimensions coordinates with the respective one in the other datapoint, squaring them, and summing them all up. \n",
    "#### If that sounded too complicated, let me show you the distance between two points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad70bfa",
   "metadata": {
    "papermill": {
     "duration": 0.010857,
     "end_time": "2022-08-09T23:04:38.543314",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.532457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$$\\LARGE p = (2, 5, 10) $$\n",
    "$$\\LARGE q = (6, 2, 9) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56373d02",
   "metadata": {
    "papermill": {
     "duration": 0.010858,
     "end_time": "2022-08-09T23:04:38.565292",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.554434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$$\\LARGE d\\left( p,q\\right) = \\sqrt {(2-6)^2 + (5-2)^2 + (10-9)^2 } $$\n",
    "$$\\LARGE = \\sqrt { 16 + 9 + 1 } $$\n",
    "$$\\LARGE = \\sqrt {26} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a9cac",
   "metadata": {
    "papermill": {
     "duration": 0.010596,
     "end_time": "2022-08-09T23:04:38.587100",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.576504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### For those of you who took basic geometry, this should always be at the back of your head as one of the most fundamental metrics of distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f4481",
   "metadata": {
    "papermill": {
     "duration": 0.010648,
     "end_time": "2022-08-09T23:04:38.608647",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.597999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### So using this formula, we would calculate the distance of all the datapoints from the specific datapoint. \n",
    "#### This is why I said before that this algorithm is not efficient as we need to calculate the dsitance between this datapoint and all the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd1a7d",
   "metadata": {
    "papermill": {
     "duration": 0.010855,
     "end_time": "2022-08-09T23:04:38.630457",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.619602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Once we got the distances, we go back to the stage above. \n",
    "#### We pick out K number of the nearest datapoints. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa1492",
   "metadata": {
    "papermill": {
     "duration": 0.010546,
     "end_time": "2022-08-09T23:04:38.651787",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.641241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Now once this is done, we observe the classes to which the K number of datasets belong to. \n",
    "#### Then, we calculate the proportions of the respective classes and assign the class with the highest proportion to the specific datapoint we were examining. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f63870",
   "metadata": {
    "papermill": {
     "duration": 0.010472,
     "end_time": "2022-08-09T23:04:38.673014",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.662542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Simple right? \n",
    "<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://images.unsplash.com/photo-1621451683587-8be65b8b975c?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxzZWFyY2h8Mnx8c3VycHJpc2VkfGVufDB8fDB8fA%3D%3D&auto=format&fit=crop&w=500&q=60\" style=\"width:50%;height:50%;margin:auto;\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1282005f",
   "metadata": {
    "papermill": {
     "duration": 0.010433,
     "end_time": "2022-08-09T23:04:38.694166",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.683733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "#### Unlike other models, there is no 'training' needed here, apart from fitting all the datapoints we have currently into our computer's memory so that the model can use them to compare to the datapoint with unknown class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e0182",
   "metadata": {
    "papermill": {
     "duration": 0.010406,
     "end_time": "2022-08-09T23:04:38.715339",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.704933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Now that the explanation is out of the way, let me present to you the code behind this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f92985",
   "metadata": {
    "papermill": {
     "duration": 0.010394,
     "end_time": "2022-08-09T23:04:38.736340",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.725946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e81b6cc",
   "metadata": {
    "papermill": {
     "duration": 0.010468,
     "end_time": "2022-08-09T23:04:38.757419",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.746951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### For this notebook, I'll be using the famous wine dataset. \n",
    "#### To give you a basic overview of the dataset, it is a dataset consisting of different characteristics of wines.\n",
    "#### The target variable in this case was the quality of these different wines, provided by wine experts.\n",
    "#### Let us take a look at the dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95f1388",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:38.780265Z",
     "iopub.status.busy": "2022-08-09T23:04:38.779737Z",
     "iopub.status.idle": "2022-08-09T23:04:38.827756Z",
     "shell.execute_reply": "2022-08-09T23:04:38.826924Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.061585,
     "end_time": "2022-08-09T23:04:38.829596",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.768011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed.acidity</th>\n",
       "      <th>volatile.acidity</th>\n",
       "      <th>citric.acid</th>\n",
       "      <th>residual.sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free.sulfur.dioxide</th>\n",
       "      <th>total.sulfur.dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.078</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.99402</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.54</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.079</td>\n",
       "      <td>24.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.99650</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.063</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99516</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.066</td>\n",
       "      <td>40.5</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.59</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.077</td>\n",
       "      <td>24.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.99528</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.094</td>\n",
       "      <td>30.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.99787</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.077</td>\n",
       "      <td>18.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.99625</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.095</td>\n",
       "      <td>48.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.99541</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.70</td>\n",
       "      <td>11.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.045</td>\n",
       "      <td>12.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.99240</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.099</td>\n",
       "      <td>14.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.70</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed.acidity  volatile.acidity  citric.acid  residual.sugar  chlorides  \\\n",
       "1102            6.1              0.48         0.09            1.70      0.078   \n",
       "1421            7.5              0.40         0.18            1.60      0.079   \n",
       "1006            9.1              0.29         0.33            2.05      0.063   \n",
       "354             6.1              0.21         0.40            1.40      0.066   \n",
       "1536            6.1              0.53         0.08            1.90      0.077   \n",
       "878             8.8              0.61         0.19            4.00      0.094   \n",
       "260             7.9              0.33         0.23            1.70      0.077   \n",
       "1175            6.5              0.61         0.00            2.20      0.095   \n",
       "390             5.6              0.85         0.05            1.40      0.045   \n",
       "360             8.2              0.70         0.23            2.00      0.099   \n",
       "\n",
       "      free.sulfur.dioxide  total.sulfur.dioxide  density    pH  sulphates  \\\n",
       "1102                 18.0                  30.0  0.99402  3.45       0.54   \n",
       "1421                 24.0                  58.0  0.99650  3.34       0.58   \n",
       "1006                 13.0                  27.0  0.99516  3.26       0.84   \n",
       "354                  40.5                 165.0  0.99120  3.25       0.59   \n",
       "1536                 24.0                  45.0  0.99528  3.60       0.68   \n",
       "878                  30.0                  69.0  0.99787  3.22       0.50   \n",
       "260                  18.0                  45.0  0.99625  3.29       0.65   \n",
       "1175                 48.0                  59.0  0.99541  3.61       0.70   \n",
       "390                  12.0                  88.0  0.99240  3.56       0.82   \n",
       "360                  14.0                  81.0  0.99730  3.19       0.70   \n",
       "\n",
       "      alcohol  quality  \n",
       "1102     11.2        6  \n",
       "1421      9.4        5  \n",
       "1006     11.7        7  \n",
       "354      11.9        6  \n",
       "1536     10.3        6  \n",
       "878      10.0        6  \n",
       "260       9.3        5  \n",
       "1175     11.5        6  \n",
       "390      12.9        8  \n",
       "360       9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/red-wine-dataset/wineQualityReds.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f2e75",
   "metadata": {
    "papermill": {
     "duration": 0.011057,
     "end_time": "2022-08-09T23:04:38.852165",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.841108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### As you can see, we have 11 total features of wine and you can click [here](https://www.kaggle.com/datasets/piyushgoyal443/red-wine-dataset) if you wish to read in detail what each of the features mean.\n",
    "#### The target variable is at the right most column called 'quality'. \n",
    "#### It ranges from 0 to 10 with 10 being the best quality and 0 being the worst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3590570a",
   "metadata": {
    "papermill": {
     "duration": 0.011175,
     "end_time": "2022-08-09T23:04:38.874632",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.863457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Now as all data scientist, data analyst, machine learning engineer or whatever role you may have, one should always look at the general picture of the whoel dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37216748",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:38.898937Z",
     "iopub.status.busy": "2022-08-09T23:04:38.898386Z",
     "iopub.status.idle": "2022-08-09T23:04:38.913629Z",
     "shell.execute_reply": "2022-08-09T23:04:38.912624Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.029321,
     "end_time": "2022-08-09T23:04:38.915320",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.885999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed.acidity         1599 non-null   float64\n",
      " 1   volatile.acidity      1599 non-null   float64\n",
      " 2   citric.acid           1599 non-null   float64\n",
      " 3   residual.sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free.sulfur.dioxide   1599 non-null   float64\n",
      " 6   total.sulfur.dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e46b4c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:38.940383Z",
     "iopub.status.busy": "2022-08-09T23:04:38.939641Z",
     "iopub.status.idle": "2022-08-09T23:04:38.978525Z",
     "shell.execute_reply": "2022-08-09T23:04:38.977859Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.053179,
     "end_time": "2022-08-09T23:04:38.980221",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.927042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed.acidity</th>\n",
       "      <th>volatile.acidity</th>\n",
       "      <th>citric.acid</th>\n",
       "      <th>residual.sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free.sulfur.dioxide</th>\n",
       "      <th>total.sulfur.dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed.acidity  volatile.acidity  citric.acid  residual.sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free.sulfur.dioxide  total.sulfur.dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd85d4fb",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:39.006165Z",
     "iopub.status.busy": "2022-08-09T23:04:39.005638Z",
     "iopub.status.idle": "2022-08-09T23:04:39.009695Z",
     "shell.execute_reply": "2022-08-09T23:04:39.009027Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.018493,
     "end_time": "2022-08-09T23:04:39.011264",
     "exception": false,
     "start_time": "2022-08-09T23:04:38.992771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (1599, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of dataframe: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8452d0d",
   "metadata": {
    "papermill": {
     "duration": 0.011302,
     "end_time": "2022-08-09T23:04:39.034321",
     "exception": false,
     "start_time": "2022-08-09T23:04:39.023019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### As we can see, this dataframe is extremely neat and clean in the sense that it doesn't mean any imputation as it has no null values.\n",
    "#### But one thing you have to remember about this algorithm, as I have mentioned above, is that KNN algorithm is sensitive to feature scaling as it allocates classes depending on the distances.\n",
    "#### Let us go ahead and standardize our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26751ec8",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:39.058599Z",
     "iopub.status.busy": "2022-08-09T23:04:39.058118Z",
     "iopub.status.idle": "2022-08-09T23:04:39.901182Z",
     "shell.execute_reply": "2022-08-09T23:04:39.900323Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.857541,
     "end_time": "2022-08-09T23:04:39.903309",
     "exception": false,
     "start_time": "2022-08-09T23:04:39.045768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52835961,  0.96187667, -1.39147228, ..., -0.57920652,\n",
       "        -0.96024611, -0.78782264],\n",
       "       [-0.29854743,  1.96744245, -1.39147228, ...,  0.1289504 ,\n",
       "        -0.58477711, -0.78782264],\n",
       "       [-0.29854743,  1.29706527, -1.18607043, ..., -0.04808883,\n",
       "        -0.58477711, -0.78782264],\n",
       "       ...,\n",
       "       [-1.1603431 , -0.09955388, -0.72391627, ...,  0.54204194,\n",
       "         0.54162988,  0.45084835],\n",
       "       [-1.39015528,  0.65462046, -0.77526673, ...,  0.30598963,\n",
       "        -0.20930812, -0.78782264],\n",
       "       [-1.33270223, -1.21684919,  1.02199944, ...,  0.01092425,\n",
       "         0.54162988,  0.45084835]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "scaled_df = scale.fit_transform(df) \n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9698c1",
   "metadata": {
    "papermill": {
     "duration": 0.011207,
     "end_time": "2022-08-09T23:04:39.926696",
     "exception": false,
     "start_time": "2022-08-09T23:04:39.915489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### How about the target variable you may ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6bddbb7",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:39.951014Z",
     "iopub.status.busy": "2022-08-09T23:04:39.950657Z",
     "iopub.status.idle": "2022-08-09T23:04:40.275507Z",
     "shell.execute_reply": "2022-08-09T23:04:40.274669Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.339124,
     "end_time": "2022-08-09T23:04:40.277339",
     "exception": false,
     "start_time": "2022-08-09T23:04:39.938215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='quality', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(15,7)})\n",
    "sns.countplot('quality', data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ed766",
   "metadata": {
    "papermill": {
     "duration": 0.011635,
     "end_time": "2022-08-09T23:04:40.301328",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.289693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### As we can see, the majority of the values for quality lies within the 5 to 7 range.\n",
    "#### There are no 0, 1, 2, 9 or 10 ratings.\n",
    "#### This obvious imbalance and bias towards the 5 to 7 quality is not the most ideal to our machine learning algorithm. \n",
    "#### This sampling bias will possibly lead to our model outputting biased results.\n",
    "#### The ideal case would be to have all the counts for quality spread out as evenly as possible.\n",
    "#### For the time being, let's just keep this fact at the back of our heads and move on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2406a3",
   "metadata": {
    "papermill": {
     "duration": 0.011534,
     "end_time": "2022-08-09T23:04:40.324680",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.313146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e1906",
   "metadata": {
    "papermill": {
     "duration": 0.011533,
     "end_time": "2022-08-09T23:04:40.347923",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.336390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Alright! Now I will proceed onto show you how the whole algorithm is written from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d240b",
   "metadata": {
    "papermill": {
     "duration": 0.011496,
     "end_time": "2022-08-09T23:04:40.371157",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.359661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4.1 Splitting Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea85135",
   "metadata": {
    "papermill": {
     "duration": 0.011477,
     "end_time": "2022-08-09T23:04:40.394345",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.382868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Let us first split our dataset. \n",
    "#### I know I have said that there is not much training to this simple algorithm, but just for convention sake :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91278819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:40.419069Z",
     "iopub.status.busy": "2022-08-09T23:04:40.418759Z",
     "iopub.status.idle": "2022-08-09T23:04:40.472289Z",
     "shell.execute_reply": "2022-08-09T23:04:40.471011Z"
    },
    "papermill": {
     "duration": 0.068117,
     "end_time": "2022-08-09T23:04:40.474137",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.406020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 11) (528, 11) (1071,) (528,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df[:,:-1], np.array(df.iloc[:,-1]), test_size=0.33, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088a991",
   "metadata": {
    "papermill": {
     "duration": 0.012063,
     "end_time": "2022-08-09T23:04:40.498669",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.486606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Now that we've got our training and test sets, let us jump into the actual mechanism of KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55de349",
   "metadata": {
    "papermill": {
     "duration": 0.012047,
     "end_time": "2022-08-09T23:04:40.523097",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.511050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4.2 Calculating Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b91d4a",
   "metadata": {
    "papermill": {
     "duration": 0.012134,
     "end_time": "2022-08-09T23:04:40.547474",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.535340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### First, the code for calculating the euclidean distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a819ea9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:40.573006Z",
     "iopub.status.busy": "2022-08-09T23:04:40.572658Z",
     "iopub.status.idle": "2022-08-09T23:04:40.577210Z",
     "shell.execute_reply": "2022-08-09T23:04:40.576409Z"
    },
    "papermill": {
     "duration": 0.019219,
     "end_time": "2022-08-09T23:04:40.578860",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.559641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def euclidean_dist(a,b):\n",
    "    distance = np.square(a - b) \n",
    "    distance = np.sum(distance)\n",
    "    distance = np.sqrt(distance) \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d1e93",
   "metadata": {
    "papermill": {
     "duration": 0.011783,
     "end_time": "2022-08-09T23:04:40.602840",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.591057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Next, code for obtaining the distance from the test point to all the other points in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556c67ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:40.627933Z",
     "iopub.status.busy": "2022-08-09T23:04:40.627608Z",
     "iopub.status.idle": "2022-08-09T23:04:40.632045Z",
     "shell.execute_reply": "2022-08-09T23:04:40.631356Z"
    },
    "papermill": {
     "duration": 0.018772,
     "end_time": "2022-08-09T23:04:40.633476",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.614704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distance_from_all_training(test_point):\n",
    "    dist_array = np.array([])\n",
    "    for train_point in X_train:\n",
    "        dist = euclidean_dist(test_point, train_point)\n",
    "        dist_array = np.append(dist_array,dist)\n",
    "    return dist_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265e52fd",
   "metadata": {
    "papermill": {
     "duration": 0.011714,
     "end_time": "2022-08-09T23:04:40.657081",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.645367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4.3 Picking out K closest points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21989b79",
   "metadata": {
    "papermill": {
     "duration": 0.012227,
     "end_time": "2022-08-09T23:04:40.681499",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.669272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Now the code for combining all of the above into a function that takes in the training dataset, a set of test features and the number k.\n",
    "#### This functino would return us the predictions for each datapoint in the test_feature input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3568adde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:40.707126Z",
     "iopub.status.busy": "2022-08-09T23:04:40.706567Z",
     "iopub.status.idle": "2022-08-09T23:04:40.712667Z",
     "shell.execute_reply": "2022-08-09T23:04:40.711972Z"
    },
    "papermill": {
     "duration": 0.020614,
     "end_time": "2022-08-09T23:04:40.714236",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.693622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def KNNClassifier(train_features, train_target, test_features, k = 5):\n",
    "    predictions = np.array([])\n",
    "    train_target = train_target.reshape(-1,1)\n",
    "    for test_point in test_features: \n",
    "        dist_array = distance_from_all_training(test_point).reshape(-1,1) \n",
    "        neighbors = np.concatenate((dist_array, train_target), axis = 1) \n",
    "        neighbors_sorted = neighbors[neighbors[:, 0].argsort()] \n",
    "        k_neighbors = neighbors_sorted[:k] \n",
    "        frequency = np.unique(k_neighbors[:, 1], return_counts=True)\n",
    "        target_class = frequency[0][frequency[1].argmax()] \n",
    "        predictions = np.append(predictions, target_class)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2846ab81",
   "metadata": {
    "papermill": {
     "duration": 0.011728,
     "end_time": "2022-08-09T23:04:40.737930",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.726202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4.4 Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5d6278",
   "metadata": {
    "papermill": {
     "duration": 0.011869,
     "end_time": "2022-08-09T23:04:40.761788",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.749919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Finally, before jumping in to see how our function works, we got to define our code to check the accuracy of our model.\n",
    "#### We will come up with a block of code to compare our predictions with the test target features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d6eb496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:40.787200Z",
     "iopub.status.busy": "2022-08-09T23:04:40.786920Z",
     "iopub.status.idle": "2022-08-09T23:04:40.791150Z",
     "shell.execute_reply": "2022-08-09T23:04:40.790593Z"
    },
    "papermill": {
     "duration": 0.018605,
     "end_time": "2022-08-09T23:04:40.792536",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.773931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_preds):\n",
    "    total_correct = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if int(y_test[i]) == int(y_preds[i]):\n",
    "            total_correct += 1\n",
    "    acc = total_correct/len(y_test) # Getting the proportion\n",
    "    return acc*100 # In percentage form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1600462",
   "metadata": {
    "papermill": {
     "duration": 0.01171,
     "end_time": "2022-08-09T23:04:40.816269",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.804559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4.5 Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90496ded",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:40.842233Z",
     "iopub.status.busy": "2022-08-09T23:04:40.841678Z",
     "iopub.status.idle": "2022-08-09T23:04:48.323497Z",
     "shell.execute_reply": "2022-08-09T23:04:48.322664Z"
    },
    "papermill": {
     "duration": 7.497648,
     "end_time": "2022-08-09T23:04:48.325973",
     "exception": false,
     "start_time": "2022-08-09T23:04:40.828325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = KNNClassifier(X_train, y_train, X_test, k = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1265b43",
   "metadata": {
    "papermill": {
     "duration": 0.0119,
     "end_time": "2022-08-09T23:04:48.350274",
     "exception": false,
     "start_time": "2022-08-09T23:04:48.338374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Let us check the accuracy of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db6b097f",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:48.375509Z",
     "iopub.status.busy": "2022-08-09T23:04:48.375016Z",
     "iopub.status.idle": "2022-08-09T23:04:48.380038Z",
     "shell.execute_reply": "2022-08-09T23:04:48.379201Z"
    },
    "papermill": {
     "duration": 0.019525,
     "end_time": "2022-08-09T23:04:48.381625",
     "exception": false,
     "start_time": "2022-08-09T23:04:48.362100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 55.30\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(y_test, pred)\n",
    "print('Model accuracy = {:.2f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9630f19",
   "metadata": {
    "papermill": {
     "duration": 0.011645,
     "end_time": "2022-08-09T23:04:48.405609",
     "exception": false,
     "start_time": "2022-08-09T23:04:48.393964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Let's see how Sklearn's KNN model does on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d09972d",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:48.431007Z",
     "iopub.status.busy": "2022-08-09T23:04:48.430648Z",
     "iopub.status.idle": "2022-08-09T23:04:48.558437Z",
     "shell.execute_reply": "2022-08-09T23:04:48.557396Z"
    },
    "papermill": {
     "duration": 0.142713,
     "end_time": "2022-08-09T23:04:48.560164",
     "exception": false,
     "start_time": "2022-08-09T23:04:48.417451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 55.30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "model = KNN()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "acc = accuracy(y_test, preds)\n",
    "print('Model accuracy = {:.2f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad325c2c",
   "metadata": {
    "papermill": {
     "duration": 0.012014,
     "end_time": "2022-08-09T23:04:48.584482",
     "exception": false,
     "start_time": "2022-08-09T23:04:48.572468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Whao! Do you see that both the accuracies are the same. \n",
    "#### Although the accuracy is not that great to start off with, we can't blame our code for it since the Sklearn's one did not fare better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de69e3e4",
   "metadata": {
    "papermill": {
     "duration": 0.012059,
     "end_time": "2022-08-09T23:04:48.609037",
     "exception": false,
     "start_time": "2022-08-09T23:04:48.596978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Let us take one additional step and see how the random forest algorithm fares for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "296fecf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-09T23:04:48.635378Z",
     "iopub.status.busy": "2022-08-09T23:04:48.634700Z",
     "iopub.status.idle": "2022-08-09T23:04:48.988536Z",
     "shell.execute_reply": "2022-08-09T23:04:48.987757Z"
    },
    "papermill": {
     "duration": 0.369002,
     "end_time": "2022-08-09T23:04:48.990345",
     "exception": false,
     "start_time": "2022-08-09T23:04:48.621343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 66.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "acc = accuracy(y_test,preds)\n",
    "print('Model accuracy = {:.2f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb7ff9",
   "metadata": {
    "papermill": {
     "duration": 0.01184,
     "end_time": "2022-08-09T23:04:49.014809",
     "exception": false,
     "start_time": "2022-08-09T23:04:49.002969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### We can see that the random forest classifier does better than our KNN model.\n",
    "#### There is a possibility that our KNN model may fare better with some hyperparameter tuning, the hyperparameter k.\n",
    "#### However, KNN is a very simple model so it would be wise to not expect too much from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa3c725",
   "metadata": {
    "papermill": {
     "duration": 0.011996,
     "end_time": "2022-08-09T23:04:49.039053",
     "exception": false,
     "start_time": "2022-08-09T23:04:49.027057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a9f05",
   "metadata": {
    "papermill": {
     "duration": 0.011817,
     "end_time": "2022-08-09T23:04:49.062929",
     "exception": false,
     "start_time": "2022-08-09T23:04:49.051112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### As we saw, implementing KNN from scratch really isn't too difficult a task.\n",
    "#### You just need to understand what K represents and how this algorithm assigns classes to new datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c3637",
   "metadata": {
    "papermill": {
     "duration": 0.011824,
     "end_time": "2022-08-09T23:04:49.087296",
     "exception": false,
     "start_time": "2022-08-09T23:04:49.075472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### With that, I hope you learnt the mechanics behind the KNN model.\n",
    "#### If you did, do remember to upvote this notebook and check out my other notebooks on more machine learning algorithms explanation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff764ccf",
   "metadata": {
    "papermill": {
     "duration": 0.011809,
     "end_time": "2022-08-09T23:04:49.111197",
     "exception": false,
     "start_time": "2022-08-09T23:04:49.099388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e97dee3",
   "metadata": {
    "papermill": {
     "duration": 0.012017,
     "end_time": "2022-08-09T23:04:49.135259",
     "exception": false,
     "start_time": "2022-08-09T23:04:49.123242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* https://towardsdatascience.com/ml-from-scratch-k-nearest-neighbors-classifier-3fc51438346b\n",
    "* https://medium.com/analytics-vidhya/k-nearest-neighbor-the-maths-behind-it-how-it-works-and-an-example-f1de1208546c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.67488,
   "end_time": "2022-08-09T23:04:49.766449",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-09T23:04:31.091569",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
